{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a114fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "from tfx import v1 as tfx\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_for_export\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfx_root = tfx.__path__[0]\n",
    "_account_root = os.path.join(_tfx_root, 'examples/account')\n",
    "_serving_model_dir = os.path.join(tempfile.mkdtemp(), 'serving_model/account_simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da114c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b960a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen = tfx.components.CsvExampleGen(input_base='/home/jupyter/data')\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d325e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile component.py\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from tfx import types\n",
    "from tfx.dsl.components.base import base_component\n",
    "from tfx.dsl.components.base import executor_spec\n",
    "from tfx.types import channel_utils\n",
    "from tfx.types import standard_artifacts\n",
    "from tfx.types.component_spec import ChannelParameter\n",
    "from tfx.types.component_spec import ExecutionParameter\n",
    "\n",
    "import executor\n",
    "\n",
    "class DownSampleSpec(types.ComponentSpec):\n",
    "\n",
    "  PARAMETERS = {\n",
    "      'ratio': ExecutionParameter(type=int),\n",
    "  }\n",
    "  INPUTS = {\n",
    "      'input_data': ChannelParameter(type=standard_artifacts.Examples),\n",
    "  }\n",
    "  OUTPUTS = {\n",
    "      'output_data': ChannelParameter(type=standard_artifacts.Examples),\n",
    "  }\n",
    "\n",
    "\n",
    "class DownSample(base_component.BaseComponent):\n",
    "\n",
    "  SPEC_CLASS = DownSampleSpec\n",
    "  EXECUTOR_SPEC = executor_spec.ExecutorClassSpec(executor.Executor)\n",
    "\n",
    "  def __init__(self,\n",
    "               input_data: types.Channel = None,\n",
    "               output_data: types.Channel = None,\n",
    "               ratio: Optional[int] = 50):\n",
    "\n",
    "    if not output_data:\n",
    "        output_data = channel_utils.as_channel([standard_artifacts.Examples()])\n",
    "\n",
    "    spec = DownSampleSpec(input_data=input_data,\n",
    "                              output_data=output_data, ratio=ratio)\n",
    "    super().__init__(spec=spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile executor.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from tfx import types\n",
    "from tfx.dsl.components.base import base_executor\n",
    "from tfx.dsl.io import fileio\n",
    "from tfx.types import artifact_utils\n",
    "from tfx.utils import io_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "def downsamplefile(input_dir, output_dir, filename, ratio):\n",
    "    input_uri = os.path.join(input_dir, filename)\n",
    "    output_uri = os.path.join(output_dir, filename) \n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(input_uri, compression_type=\"GZIP\")\n",
    "    \n",
    "    def decode_fn(record_bytes):\n",
    "        return tf.io.parse_single_example(\n",
    "           record_bytes,\n",
    "           {\"Digit0\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"Digit1\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"Digit2\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"Digit3\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"Digit4\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"Digit5\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"Digit6\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"Digit7\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "            \"Valid\":  tf.io.FixedLenFeature([], dtype=tf.string)}\n",
    "     ) \n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_uri, options=tf.io.TFRecordOptions(compression_type=\"GZIP\")) as writer:\n",
    "        for sample in dataset.map(decode_fn):\n",
    "             if sample['Valid'] == \"True\" or (sample['Valid'] == \"False\" and random.randint(1,ratio) == 1):\n",
    "                record_bytes = tf.train.Example(features=tf.train.Features(feature={\n",
    "                \"Digit0\": tf.train.Feature(int64_list=tf.train.Int64List(value=[sample['Digit0']])),\n",
    "                \"Digit1\": tf.train.Feature(int64_list=tf.train.Int64List(value=[sample['Digit1']])),\n",
    "                \"Digit2\": tf.train.Feature(int64_list=tf.train.Int64List(value=[sample['Digit2']])),\n",
    "                \"Digit3\": tf.train.Feature(int64_list=tf.train.Int64List(value=[sample['Digit3']])),\n",
    "                \"Digit4\": tf.train.Feature(int64_list=tf.train.Int64List(value=[sample['Digit4']])),\n",
    "                \"Digit5\": tf.train.Feature(int64_list=tf.train.Int64List(value=[sample['Digit5']])),\n",
    "                \"Digit6\": tf.train.Feature(int64_list=tf.train.Int64List(value=[sample['Digit6']])),\n",
    "                \"Digit7\": tf.train.Feature(int64_list=tf.train.Int64List(value=[sample['Digit7']])),\n",
    "                \"Valid\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[sample['Valid'].numpy()]))\n",
    "                })).SerializeToString()\n",
    "            \n",
    "                writer.write(record_bytes)      \n",
    "\n",
    "class Executor(base_executor.BaseExecutor):\n",
    "    \n",
    "    def Do(self, input_dict: Dict[str, List[types.Artifact]],\n",
    "         output_dict: Dict[str, List[types.Artifact]],\n",
    "         exec_properties: Dict[str, Any]) -> None:\n",
    "\n",
    "        self._log_startup(input_dict, output_dict, exec_properties)\n",
    "\n",
    "        input_artifact = artifact_utils.get_single_instance(input_dict['input_data'])\n",
    "        output_artifact = artifact_utils.get_single_instance(output_dict['output_data'])\n",
    "        output_artifact.split_names = input_artifact.split_names\n",
    "        ratio = exec_properties['ratio']\n",
    "        \n",
    "        split_to_instance = {}\n",
    "\n",
    "        for split in json.loads(input_artifact.split_names):\n",
    "            uri = artifact_utils.get_split_uri([input_artifact], split)\n",
    "            split_to_instance[split] = uri\n",
    "\n",
    "        for split, instance in split_to_instance.items():\n",
    "            input_dir = instance\n",
    "            output_dir = artifact_utils.get_split_uri([output_artifact], split)\n",
    "            for filename in fileio.listdir(input_dir):          \n",
    "                if \"train\" in input_dir:\n",
    "                    io_utils.copy_dir(input_dir,output_dir)\n",
    "                    downsamplefile(input_dir, output_dir, filename, ratio)\n",
    "                else:\n",
    "                    input_uri = os.path.join(input_dir, filename)\n",
    "                    output_uri = os.path.join(output_dir, filename)\n",
    "                    io_utils.copy_file(src=input_uri, dst=output_uri, overwrite=True)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0295e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component import DownSample\n",
    "\n",
    "downsample_gen = DownSample(input_data=example_gen.outputs['examples'], ratio=50)\n",
    "context.run(downsample_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33308814",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = tfx.components.StatisticsGen(\n",
    "    examples=downsample_gen.outputs['output_data'])\n",
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen = tfx.components.SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=False)\n",
    "context.run(schema_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = tfx.components.ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'])\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e5bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "_account_transform_module_file = 'account_transform.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_account_transform_module_file}\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "DIGIT_KEYS = ['Digit0','Digit1','Digit2','Digit3','Digit4','Digit5','Digit6','Digit7']\n",
    "LABEL_KEY = 'Valid'\n",
    "\n",
    "def _transformed_name(key):\n",
    "  return key + '_xf'\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "\n",
    "    outputs = {}\n",
    "    for key in DIGIT_KEYS:\n",
    "        outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n",
    "          \n",
    "    outputs[_transformed_name(LABEL_KEY)] = tft.compute_and_apply_vocabulary(_fill_in_missing(inputs[LABEL_KEY]))\n",
    "                                                                           \n",
    "    return outputs\n",
    "\n",
    "def _fill_in_missing(x):\n",
    "  if not isinstance(x, tf.sparse.SparseTensor):\n",
    "    return x\n",
    "\n",
    "  default_value = '' if x.dtype == tf.string else 0\n",
    "  return tf.squeeze(\n",
    "      tf.sparse.to_dense(\n",
    "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
    "          default_value),\n",
    "      axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38734d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfx.components.Transform(\n",
    "    examples=downsample_gen.outputs['output_data'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    module_file=os.path.abspath(_account_transform_module_file))\n",
    "context.run(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'Split-train')\n",
    "tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                      for name in os.listdir(train_uri)]\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "_account_trainer_module_file = 'account_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_account_trainer_module_file}\n",
    "\n",
    "from typing import List, Text\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "\n",
    "DIGIT_KEYS = ['Digit0','Digit1','Digit2','Digit3','Digit4','Digit5','Digit6','Digit7']\n",
    "LABEL_KEY = 'Valid'\n",
    "\n",
    "def _transformed_name(key):\n",
    "  return key + '_xf'\n",
    "\n",
    "def _transformed_names(keys):\n",
    "  return [_transformed_name(key) for key in keys]\n",
    "\n",
    "def _input_fn(file_pattern: List[Text],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              tf_transform_output: tft.TFTransformOutput,\n",
    "              batch_size: int = 200) -> tf.data.Dataset:\n",
    "    return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_transformed_name(LABEL_KEY)),\n",
    "      tf_transform_output.transformed_metadata.schema)\n",
    "\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "\n",
    "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "    \n",
    "  train_dataset = _input_fn(fn_args.train_files, fn_args.data_accessor, \n",
    "                            tf_transform_output, 40)\n",
    "  eval_dataset = _input_fn(fn_args.eval_files, fn_args.data_accessor, \n",
    "                           tf_transform_output, 40)\n",
    "\n",
    "  visible = { colname: tf.keras.layers.Input(name = colname, shape=(), dtype=tf.int32) for colname in _transformed_names(DIGIT_KEYS) }\n",
    "  feature_columns = [tf.feature_column.numeric_column(key, shape=()) for key in _transformed_names(DIGIT_KEYS)]\n",
    "\n",
    "  features = tf.keras.layers.DenseFeatures(feature_columns)(visible)\n",
    "  hidden1 = tf.keras.layers.Dense(256, activation='relu')(features) \n",
    "  hidden2 = tf.keras.layers.Dense(128, activation='relu')(hidden1)\n",
    "  output = tf.keras.layers.Dense(1, activation='sigmoid')(hidden2)\n",
    "  model = tf.keras.Model(inputs=visible, outputs=output)\n",
    "  model.compile(loss='mse', optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "      \n",
    "  signatures = {\n",
    "      'serving_default':\n",
    "          _get_serve_tf_examples_fn(model,\n",
    "                                    tf_transform_output).get_concrete_function(\n",
    "                                        tf.TensorSpec(\n",
    "                                            shape=[None],\n",
    "                                            dtype=tf.string,\n",
    "                                            name='examples')),\n",
    "  }\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)\n",
    "    \n",
    "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "\n",
    "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "    @tf.function\n",
    "    def serve_tf_examples_fn(serialized_tf_examples):\n",
    "        feature_spec = tf_transform_output.raw_feature_spec()\n",
    "        if not model.tft_layer.built:\n",
    "            parsed_features_with_label = tf.io.parse_example(\n",
    "                serialized_tf_examples, feature_spec)\n",
    "            _ = model.tft_layer(parsed_features_with_label)\n",
    "        feature_spec.pop(LABEL_KEY)\n",
    "        parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
    "        transformed_features = model.tft_layer(parsed_features)\n",
    "        return model(transformed_features)\n",
    "    return serve_tf_examples_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31952d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = tfx.components.Trainer(\n",
    "    module_file=os.path.abspath(_account_trainer_module_file),\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    train_args=tfx.proto.TrainArgs(num_steps=10000),\n",
    "    eval_args=tfx.proto.EvalArgs(num_steps=5000))\n",
    "context.run(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da164e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_KEY = 'Valid'\n",
    "\n",
    "def _transformed_name(key):\n",
    "  return key + '_xf'\n",
    "\n",
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[tfma.ModelSpec(signature_name=\"serving_default\", label_key=_transformed_name(LABEL_KEY), preprocessing_function_names=[\"tft_layer\"])],\n",
    "\n",
    "    metrics_specs=[\n",
    "        tfma.MetricsSpec(\n",
    "            metrics=[\n",
    "                tfma.MetricConfig(class_name='FalsePositives'),\n",
    "                tfma.MetricConfig(class_name='TruePositives'),\n",
    "                tfma.MetricConfig(class_name='FalseNegatives'),\n",
    "                tfma.MetricConfig(class_name='TrueNegatives'),\n",
    "                tfma.MetricConfig(class_name='ExampleCount'),\n",
    "                tfma.MetricConfig(class_name='BinaryAccuracy',              \n",
    "                  threshold=tfma.MetricThreshold(\n",
    "                      value_threshold=tfma.GenericValueThreshold(\n",
    "                          lower_bound={'value': 0.5}),\n",
    "                      change_threshold=tfma.GenericChangeThreshold(\n",
    "                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                          absolute={'value': -1e-10})))\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf26281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resolver = tfx.dsl.Resolver(\n",
    "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
    "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
    "      model_blessing=tfx.dsl.Channel(\n",
    "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
    "              'latest_blessed_model_resolver')\n",
    "context.run(model_resolver)\n",
    "\n",
    "evaluator = tfx.components.Evaluator(\n",
    "    examples=downsample_gen.outputs['output_data'],\n",
    "    model=trainer.outputs['model'],\n",
    "    baseline_model=model_resolver.outputs['model'],\n",
    "    eval_config=eval_config)\n",
    "context.run(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ba29a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:10:20.553979Z",
     "iopub.status.busy": "2021-07-27T09:10:20.552932Z",
     "iopub.status.idle": "2021-07-27T09:10:20.570200Z",
     "shell.execute_reply": "2021-07-27T09:10:20.569661Z"
    },
    "id": "pyis6iy0HLdi"
   },
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
    "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
    "tfma_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75926b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:10:20.599525Z",
     "iopub.status.busy": "2021-07-27T09:10:20.598809Z",
     "iopub.status.idle": "2021-07-27T09:10:20.739100Z",
     "shell.execute_reply": "2021-07-27T09:10:20.738536Z"
    },
    "id": "FZmiRtg6TKtR"
   },
   "outputs": [],
   "source": [
    "blessing_uri = evaluator.outputs['blessing'].get()[0].uri\n",
    "!ls -l {blessing_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5b073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T09:10:20.757214Z",
     "iopub.status.busy": "2021-07-27T09:10:20.756311Z",
     "iopub.status.idle": "2021-07-27T09:10:20.823881Z",
     "shell.execute_reply": "2021-07-27T09:10:20.824324Z"
    },
    "id": "r45nQ69eikc9"
   },
   "outputs": [],
   "source": [
    "pusher = tfx.components.Pusher(\n",
    "    model=trainer.outputs['model'],\n",
    "    model_blessing=evaluator.outputs['blessing'],\n",
    "    push_destination=tfx.proto.PushDestination(\n",
    "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "            base_directory=_serving_model_dir)))\n",
    "context.run(pusher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_uri = pusher.outputs['pushed_model'].get()[0].uri\n",
    "%env MODELDIR = {push_uri+'/'}\n",
    "!saved_model_cli run --dir $MODELDIR --tag_set serve --signature_def serving_default \\\n",
    "  --input_examples 'examples=[{\"Digit0\":[3],\"Digit1\":[1],\"Digit2\":[6],\"Digit3\":[0],\"Digit4\":[0],\"Digit5\":[4],\"Digit6\":[9],\"Digit7\":[4]}]'"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
